{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c46d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this model is 98.46153846153847%\n"
     ]
    }
   ],
   "source": [
    "# Module imports.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "# Dataframe setup.\n",
    "\n",
    "df_raw = pd.read_csv(\"parkinsons.data\")\n",
    "df_raw.pop(\"name\")\n",
    "y = df_raw.iloc[:,16]\n",
    "X = df_raw.iloc[:,:16]\n",
    "df_rawSize = len(df_raw.index)\n",
    "\n",
    "# Logistic regression model.\n",
    "\n",
    "reg_log = LogisticRegression()\n",
    "reg_log.fit(X, y)\n",
    "y_pred_reg = reg_log.predict(X)\n",
    "\n",
    "# Support vector machine model.\n",
    "\n",
    "svm_pipe = Pipeline([(\"model\", SVC())])\n",
    "svm_pipe.set_params(model__C = 10,\n",
    "                    model__decision_function_shape = \"ovr\",\n",
    "                    model__gamma = 0.1,\n",
    "                    model__kernel = \"rbf\")\n",
    "svm_pipe.fit(X, y)\n",
    "y_pred_svm = svm_pipe.predict(X)\n",
    "\n",
    "# Random forest model.\n",
    "\n",
    "max_depth_rf = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth_rf.append(None)\n",
    "random_grid_rf = {\"n_estimators\": [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "               \"max_features\": [\"auto\", \"sqrt\"],\n",
    "               \"max_depth\": max_depth_rf,\n",
    "               \"min_samples_split\": [2, 5, 10],\n",
    "               \"min_samples_leaf\": [1, 2, 4],\n",
    "               \"bootstrap\": [True, False]}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid_rf, \n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose = 0, \n",
    "                               n_jobs = -1)\n",
    "rf_random.fit(X, y)\n",
    "rf_params = rf_random.best_params_\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators = rf_params.get(\"n_estimators\", None),\n",
    "                              min_samples_split = rf_params.get(\"min_samples_split\", None),\n",
    "                              min_samples_leaf = rf_params.get(\"min_samples_leaf\", None),\n",
    "                              max_features = rf_params.get(\"max_features\", None),\n",
    "                              max_depth = rf_params.get(\"max_depth\", None),\n",
    "                              bootstrap = rf_params.get(\"bootstrap\", None))\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "rf_model.fit(X, y)\n",
    "y_pred_rf = rf_model.predict(X)\n",
    "\n",
    "# Neural network model.\n",
    "\n",
    "nn_model = Sequential([keras.layers.Flatten(input_shape = (16,)),\n",
    "                        keras.layers.Dense(16, activation = tf.nn.relu),\n",
    "                        keras.layers.Dense(16, activation = tf.nn.relu),\n",
    "                        keras.layers.Dense(1, activation = tf.nn.sigmoid),\n",
    "                        ])\n",
    "nn_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "nn_model.fit(X, y, epochs = 500, batch_size = 1, verbose = 0)\n",
    "y_pred_nn = nn_model.predict(X)\n",
    "\n",
    "# Decision tree model.\n",
    "\n",
    "parameters_dt = {'max_depth' : (3, 5, 7, 9, 10, 30, 50, 70, 90, 100),\n",
    "              'criterion' : ('gini', 'entropy'),\n",
    "              'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "              'min_samples_split' : (2, 4, 6)}\n",
    "\n",
    "dt_grid = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions = parameters_dt, cv = 5, verbose = 0)\n",
    "dt_grid.fit(X, y)\n",
    "dt_params = dt_grid.best_params_\n",
    "\n",
    "clf_model = tree.DecisionTreeClassifier(max_depth = dt_params.get(\"max_depth\", None),\n",
    "                                        max_features = dt_params.get(\"max_features\", None),\n",
    "                                        min_samples_split = dt_params.get(\"min_samples_split\", None),\n",
    "                                        criterion = dt_params.get(\"criterion\", None))\n",
    "clf_model.fit(X, y)\n",
    "y_pred_clf = clf_model.predict(X)\n",
    "\n",
    "# Neural network binary conversion.\n",
    "y_pred_nn = y_pred_nn.tolist()\n",
    "for i in range(df_rawSize):\n",
    "    j = y_pred_nn.pop(0)[0]\n",
    "    if j == 0.5:\n",
    "        j = 1\n",
    "    else:\n",
    "        j = round(j)\n",
    "    y_pred_nn.append(j)\n",
    "    \n",
    "# Weighting calculations.\n",
    "\n",
    "y_pred_regZero = metrics.classification_report(y, y_pred_reg, output_dict = True).get(\"0\", {}).get(\"precision\", None)\n",
    "y_pred_regOne = metrics.classification_report(y, y_pred_reg, output_dict = True).get(\"1\", {}).get(\"precision\", None)\n",
    "y_pred_svmZero = metrics.classification_report(y, y_pred_svm, output_dict = True).get(\"0\", {}).get(\"precision\", None)\n",
    "y_pred_svmOne = metrics.classification_report(y, y_pred_svm, output_dict = True).get(\"1\", {}).get(\"precision\", None)\n",
    "y_pred_rfZero = metrics.classification_report(y, y_pred_rf, output_dict = True).get(\"0\", {}).get(\"precision\", None)\n",
    "y_pred_rfOne = metrics.classification_report(y, y_pred_rf, output_dict = True).get(\"1\", {}).get(\"precision\", None)\n",
    "y_pred_nnZero = metrics.classification_report(y, y_pred_nn, output_dict = True).get(\"0\", {}).get(\"precision\", None)\n",
    "y_pred_nnOne = metrics.classification_report(y, y_pred_nn, output_dict = True).get(\"1\", {}).get(\"precision\", None)\n",
    "y_pred_clfZero = metrics.classification_report(y, y_pred_clf, output_dict = True).get(\"0\", {}).get(\"precision\", None)\n",
    "y_pred_clfOne = metrics.classification_report(y, y_pred_clf, output_dict = True).get(\"1\", {}).get(\"precision\", None)\n",
    "\n",
    "# Weighted voting occurance.\n",
    "\n",
    "predictions = []\n",
    "confidence = []\n",
    "for i in range(df_rawSize):\n",
    "    totalOne = 0\n",
    "    if y_pred_reg[i] == 1:\n",
    "        totalOne += round(y_pred_regOne * 100)\n",
    "    else:\n",
    "        totalOne += round((1 - y_pred_regZero) * 100)\n",
    "    if y_pred_svm[i] == 1:\n",
    "        totalOne += round(y_pred_svmOne * 100)\n",
    "    else:\n",
    "        totalOne += round((1 - y_pred_svmZero) * 100)\n",
    "    if y_pred_rf[i] == 1:\n",
    "        totalOne += round(y_pred_rfOne * 100)\n",
    "    else:\n",
    "        totalOne += round((1 - y_pred_rfZero) * 100)\n",
    "    if y_pred_nn[i] == 1:\n",
    "        totalOne += round(y_pred_nnOne * 100)\n",
    "    else:\n",
    "        totalOne += round((1 - y_pred_nnZero) * 100)\n",
    "    if y_pred_clf[i] == 1:\n",
    "        totalOne += round(y_pred_clfOne * 100)\n",
    "    else:\n",
    "        totalOne += round((1 - y_pred_clfZero) * 100)\n",
    "    if totalOne / 500 == 0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(round(totalOne / 500))\n",
    "    confidence.append(totalOne / 500)\n",
    "\n",
    "# Comparison of prediction to status.\n",
    "\n",
    "df_raw[\"predictions\"] = predictions\n",
    "df_raw[\"confidence\"] = confidence\n",
    "totalResults = []\n",
    "for i in range(df_rawSize):\n",
    "    if df_raw.at[i, \"status\"] == df_raw.at[i, \"predictions\"]:\n",
    "        totalResults.append(1)\n",
    "    else:\n",
    "        totalResults.append(0)\n",
    "        \n",
    "# Accuracy report.\n",
    "\n",
    "print(\"The accuracy of this model is \" + str(sum(totalResults) / len(totalResults) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25809d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
